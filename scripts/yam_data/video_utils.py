"""
Video processing utilities for YAMS data conversion.

This module contains optimized video encoding/decoding functions with hardware acceleration support.
"""

import os
import subprocess
import tempfile
from pathlib import Path
from typing import List, Tuple, Optional
import numpy as np
import cv2
import ffmpeg
import warnings
warnings.filterwarnings("ignore")

# Try to import faster libraries
try:
    import av  # PyAV for faster video decoding
    HAS_PYAV = True
except ImportError:
    HAS_PYAV = False

try:
    import torch
    import torchvision.transforms.functional as TF
    HAS_TORCH = True
except ImportError:
    HAS_TORCH = False


def detect_hardware_encoder() -> List[str]:
    """Detect available hardware video encoders."""
    encoders = []
    
    # Test for NVIDIA NVENC
    try:
        result = subprocess.run(['ffmpeg', '-hide_banner', '-encoders'], 
                              capture_output=True, text=True, timeout=10)
        if 'h264_nvenc' in result.stdout:
            encoders.append('h264_nvenc')
        if 'hevc_nvenc' in result.stdout:
            encoders.append('hevc_nvenc')
    except:
        pass
    
    # Test for Intel Quick Sync
    try:
        result = subprocess.run(['ffmpeg', '-hide_banner', '-encoders'], 
                              capture_output=True, text=True, timeout=10)
        if 'h264_qsv' in result.stdout:
            encoders.append('h264_qsv')
    except:
        pass
    
    # Test for AMD VCE
    try:
        result = subprocess.run(['ffmpeg', '-hide_banner', '-encoders'], 
                              capture_output=True, text=True, timeout=10)
        if 'h264_amf' in result.stdout:
            encoders.append('h264_amf')
    except:
        pass
    
    # Fallback to fast software encoders
    encoders.extend(['libx264', 'libx265'])
    
    return encoders


def encode_video_hardware(frames: List[np.ndarray], save_path: Path, fps: int = 30, encoder: str = None):
    """Encode frames using hardware acceleration when available."""
    if not frames:
        return
    
    if encoder is None:
        available_encoders = detect_hardware_encoder()
        encoder = available_encoders[0] if available_encoders else 'libx264'
    
    height, width, _ = frames[0].shape
    
    # Create temporary file for input
    with tempfile.NamedTemporaryFile(suffix='.raw', delete=False) as temp_file:
        temp_path = temp_file.name
        # Write frames as raw video data
        frame_data = np.stack(frames).astype(np.uint8)
        temp_file.write(frame_data.tobytes())
    
    try:
        # Configure encoder-specific settings
        if 'nvenc' in encoder:
            # NVIDIA NVENC settings for maximum speed
            encoder_args = {
                'vcodec': encoder,
                'preset': 'p1',  # Fastest preset for NVENC
                'tune': 'ull',   # Ultra-low latency
                'rc': 'vbr',     # Variable bitrate
                'cq': '23',      # Quality level
                'b:v': '5M',     # Target bitrate
                'maxrate': '10M',
                'bufsize': '10M',
                'gpu': '0'       # Use first GPU
            }
        elif 'qsv' in encoder:
            # Intel Quick Sync settings
            encoder_args = {
                'vcodec': encoder,
                'preset': 'veryfast',
                'global_quality': '23',
                'look_ahead': '0'
            }
        elif 'amf' in encoder:
            # AMD VCE settings
            encoder_args = {
                'vcodec': encoder,
                'quality': 'speed',
                'rc': 'vbr_peak',
                'qp_i': '22',
                'qp_p': '24'
            }
        else:
            # Fast software encoding fallback
            encoder_args = {
                'vcodec': encoder,
                'preset': 'ultrafast',
                'crf': '23',
                'tune': 'fastdecode'
            }
        
        # Common settings
        encoder_args.update({
            'pix_fmt': 'yuv420p',
            'r': fps,
            'movflags': '+faststart'  # Enable fast start for web playback
        })
        
        # Build ffmpeg command
        input_stream = ffmpeg.input(
            temp_path, 
            format='rawvideo', 
            pix_fmt='rgb24', 
            s=f'{width}x{height}', 
            framerate=fps
        )
        
        output_stream = ffmpeg.output(input_stream, str(save_path), **encoder_args)
        
        # Run with minimal overhead
        ffmpeg.run(
            output_stream,
            overwrite_output=True,
            capture_stdout=True,
            capture_stderr=True,
            quiet=True
        )
        
    except Exception as e:
        print(f"Hardware encoding failed with {encoder}, falling back to libx264: {e}")
        # Fallback to basic libx264
        try:
            (
                ffmpeg
                .input(temp_path, format='rawvideo', pix_fmt='rgb24', s=f'{width}x{height}', framerate=fps)
                .output(
                    str(save_path),
                    vcodec='libx264',
                    preset='ultrafast',
                    crf=23,
                    pix_fmt='yuv420p',
                    r=fps
                )
                .overwrite_output()
                .run(capture_stdout=True, capture_stderr=True, quiet=True)
            )
        except Exception as e2:
            pass  # Silent fallback failure
    finally:
        # Clean up temporary file
        try:
            os.unlink(temp_path)
        except:
            pass


def extract_video_frames_fast(video_path: Path) -> np.ndarray:
    """Extract frames from video using the fastest available method."""
    if HAS_PYAV:
        return extract_video_frames_pyav(video_path)
    else:
        return extract_video_frames_opencv_optimized(video_path)


def extract_video_frames_pyav(video_path: Path) -> np.ndarray:
    """Extract frames using PyAV (much faster than OpenCV)."""
    try:
        container = av.open(str(video_path))
        video_stream = container.streams.video[0]
        
        # Pre-allocate array
        frame_count = video_stream.frames
        if frame_count == 0:  # Fallback if frame count unknown
            frame_count = int(video_stream.duration * video_stream.average_rate)
        
        width = video_stream.width
        height = video_stream.height
        frames = np.empty((frame_count, height, width, 3), dtype=np.uint8)
        
        frame_idx = 0
        for frame in container.decode(video_stream):
            if frame_idx >= frame_count:
                break
            # Convert to RGB numpy array
            frames[frame_idx] = frame.to_ndarray(format='rgb24')
            frame_idx += 1
        
        container.close()
        return frames[:frame_idx]
        
    except Exception as e:
        # Fallback to OpenCV silently
        return extract_video_frames_opencv_optimized(video_path)


def extract_video_frames_opencv_optimized(video_path: Path) -> np.ndarray:
    """Optimized OpenCV video extraction with better buffering."""
    cap = cv2.VideoCapture(str(video_path))
    
    # Set buffer size to reduce latency
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
    
    # Get properties
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    # Pre-allocate with exact size
    frames = np.empty((frame_count, height, width, 3), dtype=np.uint8)
    
    # Read all frames in batch
    frame_idx = 0
    while frame_idx < frame_count:
        ret, frame = cap.read()
        if not ret:
            break
        # Direct BGR to RGB conversion
        cv2.cvtColor(frame, cv2.COLOR_BGR2RGB, dst=frames[frame_idx])
        frame_idx += 1
    
    cap.release()
    return frames[:frame_idx]


def resize_frames_vectorized(frames: np.ndarray, target_size: int) -> np.ndarray:
    """Vectorized frame resizing using the fastest available method."""
    if HAS_TORCH:
        return resize_frames_torch(frames, target_size)
    else:
        return resize_frames_numpy_vectorized(frames, target_size)


def resize_frames_torch(frames: np.ndarray, target_size: int) -> np.ndarray:
    """Ultra-fast GPU/CPU vectorized resizing using PyTorch."""
    # Convert to torch tensor (HWC -> CHW)
    tensor = torch.from_numpy(frames).permute(0, 3, 1, 2).float() / 255.0
    
    # Resize all frames at once
    resized = TF.resize(tensor, [target_size, target_size], antialias=True)
    
    # Convert back to numpy (CHW -> HWC)
    result = (resized.permute(0, 2, 3, 1) * 255).byte().numpy()
    return result


def resize_frames_numpy_vectorized(frames: np.ndarray, target_size: int) -> np.ndarray:
    """Vectorized numpy-based resizing (faster than PIL loop)."""
    n_frames, h, w, c = frames.shape
    
    # Calculate resize parameters
    scale = min(target_size / w, target_size / h)
    new_w, new_h = int(w * scale), int(h * scale)
    
    # Resize all frames using OpenCV (faster than PIL for batch)
    resized_frames = np.empty((n_frames, target_size, target_size, c), dtype=np.uint8)
    
    for i in range(n_frames):
        # Resize frame
        resized = cv2.resize(frames[i], (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        
        # Add padding
        pad_h = (target_size - new_h) // 2
        pad_w = (target_size - new_w) // 2
        
        resized_frames[i] = np.pad(
            resized, 
            ((pad_h, target_size - new_h - pad_h), 
             (pad_w, target_size - new_w - pad_w), 
             (0, 0)), 
            mode='constant', 
            constant_values=0
        )
    
    return resized_frames 